-------------------------------------------------------------- 
-------------------------PYFIT-FF----------------------------- 
-------------------------------------------------------------- 
RUN PARAMETERS: 
	  input_file          	:	input.json	 
	  src_path            	:	/home/james/bin/PYFIT/PYFIT-FF/src	 
	  run_path            	:	/home/james/bin/PYFIT/PYFIT-FF/example/	 
	  start_time          	:	2020-01-25-H18-M20-S33	 
READING DEFAULT PARAMETERS USING FILE:	/home/james/bin/PYFIT/PYFIT-FF/src/defaults.json	 
	  max_iter            	:	0	 
	  fraction_train      	:	0.8	 
	  re_randomize        	:	False	 
	  learning_rate       	:	0.25	 
	  lambda_rmse         	:	1.0	 
	  lambda_dU           	:	1.0	 
	  lambda_l1           	:	0.0	 
	  lambda_l2           	:	0.0	 
	  xtanhx              	:	True	 
	  rmse_tol            	:	1e-09	 
	  rmse_final          	:	0.0	 
	  rmse_max            	:	10.0	 
	  save_every          	:	5	 
	  u_shift             	:	0.0	 
	  train_edges         	:	True	 
	  dump_poscars        	:	False	 
	  write_lsp           	:	False	 
	  test_set_gids       	:	[]	 
	  n_rand_GIDS         	:	10	 
OVERWRITING SELECT DEFAULTS USING INPUT FILE:	input.json	 
	  pot_type            	:	NN	 
	  pot_file            	:	nn1.dat	 
	  dataset_path        	:	train.dat	 
	  max_iter            	:	1000	 
	  u_shift             	:	0.795023	 
	  test_set_gids       	:	[]	 
	  re_randomize        	:	True	 
READING NEURAL NETWORK FILE: 
	 RANDOMIZING NN MIN/MAX	=	0.250001	 
	 matrix_shape		:	torch.Size([24, 40]) 
	 matrix_shape		:	torch.Size([24, 1]) 
	 matrix_shape		:	torch.Size([24, 24]) 
	 matrix_shape		:	torch.Size([24, 1]) 
	 matrix_shape		:	torch.Size([16, 24]) 
	 matrix_shape		:	torch.Size([16, 1]) 
	 matrix_shape		:	torch.Size([1, 16]) 
	 matrix_shape		:	torch.Size([1, 1]) 
	  lsp_type            	:	5	 
	  pot_type            	:	NN	 
	  lsp_shift           	:	0.0	 
	  activation          	:	1	 
	  num_species         	:	1	 
	  species             	:	Si	 
	  atomic_weight       	:	28.0855	 
	  randomize_nn        	:	False	 
	  max_rand_wb         	:	0.250001	 
	  cutoff_dist         	:	4.5	 
	  cutoff_range        	:	0.978124	 
	  lsp_sigma           	:	1.0	 
	  lsp_lg_poly         	:	[0, 1, 2, 4, 6]	 
	  lsp_ro_val          	:	[2.25, 2.5, 2.75, 3.0, 3.25, 3.5, 3.75, 4.0]	 
	  ibaseline           	:	True	 
	  bop_param           	:	[12.1692, 6.17263, 3.11471, 0.755675, 0.404939, 0.036124, 0.650018, 0.57289]	 
	  nn_layers           	:	[40, 24, 24, 16, 1]	 
	  num_fit_param       	:	2001	 
READING DATASET FILE: 
	TOTAL NUMBER OF STRUCTURES:	3644	 
	TOTAL NUMBER OF ATOMS:		24035	 
COMPUTING NEIGHBOR LIST (NBL):	 
	NBL CONSTRUCTION TIME (SEC)	=	8.027762413024902	 
COMPUTING LOCAL STRUCTURE PARAMETERS (LSP):	 
	LSP CONSTRUCTION TIME (SEC)	=	12.122868061065674	 
PARTITIONING DATA: 
	TOTAL NUMBER OF GROUPS=	41	 
	TEST SET (UNTRAINED): 
		GID		: 	GRP-BSN-P-UNPERTURBED+ISO	 
		GID		: 	GRP-Si5_2-PENTAMER-PYRAMID-UNPERTURBED+ISO	 
		GID		: 	GRP-Si6_3-HEXAMER-EDGECAP-UNPERTURBED+ISO	 
		GID		: 	GRP-Si8_1-OCTAMER-BI-PYRAMID-UNPERTURBED+ISO	 
		GID		: 	GRP-Si3_3-TRIMER-EQ-LAT-UNPERTURBED+ISO	 
		GID		: 	GRP-Si4_2-TETRAMER-TD-UNPERTURBED+ISO	 
		GID		: 	GRP-Si4_5-TETRAMER-UNPERTURBED+ISO	 
		GID		: 	GRP-SILICENE-1-LAYER-DUMBELL-UNPERTURBED+ISO	 
		GID		: 	GRP-SILICENE-BUCKLED-BILAYER-AA^p-UNPERTURBED+ISO	 
		GID		: 	GRP-SILICENE-1-LAYER-HONEYCOMB-UNPERTURBED+ISO	 
	N_train_structures	: 	2608	 
	N_val_structures	: 	612	 
	N_test_structures	: 	424	 
	N_combined		: 	3644	 
STARTING FITTING LOOP: 
1	17597434.0	0.0	0.0	 
2	1037156.25	0.0	0.0	 
3	317141.59375	0.0	0.0	 
4	156709.859375	0.0	0.0	 
5	80771.5625	0.0	0.0	 
6	48006.6484375	0.0	0.0	 
7	28768.7578125	0.0	0.0	 
8	19137.396484375	0.0	0.0	 
9	15771.7958984375	0.0	0.0	 
10	12333.498046875	0.0	0.0	 
11	10049.0244140625	0.0	0.0	 
12	7976.2724609375	0.0	0.0	 
13	6969.486328125	0.0	0.0	 
14	6477.654296875	0.0	0.0	 
15	5984.095703125	0.0	0.0	 
16	5511.9599609375	0.0	0.0	 
17	5088.16357421875	0.0	0.0	 
18	4786.58642578125	0.0	0.0	 
19	4486.3486328125	0.0	0.0	 
20	4168.55712890625	0.0	0.0	 
21	3989.83251953125	0.0	0.0	 
22	3822.72265625	0.0	0.0	 
23	3660.793212890625	0.0	0.0	 
24	3605.447021484375	0.0	0.0	 
25	3467.199462890625	0.0	0.0	 
26	3390.49951171875	0.0	0.0	 
27	3342.94140625	0.0	0.0	 
28	3264.965087890625	0.0	0.0	 
29	3212.727783203125	0.0	0.0	 
30	3127.39697265625	0.0	0.0	 
31	3054.112548828125	0.0	0.0	 
32	2883.63818359375	0.0	0.0	 
33	2772.273681640625	0.0	0.0	 
34	2657.735595703125	0.0	0.0	 
35	2537.169921875	0.0	0.0	 
36	2398.79443359375	0.0	0.0	 
37	2350.411865234375	0.0	0.0	 
38	2300.8583984375	0.0	0.0	 
39	2213.502685546875	0.0	0.0	 
40	2110.552490234375	0.0	0.0	 
41	2066.465576171875	0.0	0.0	 
42	2004.60986328125	0.0	0.0	 
43	1928.2130126953125	0.0	0.0	 
44	1880.928466796875	0.0	0.0	 
45	1854.8359375	0.0	0.0	 
46	1811.5498046875	0.0	0.0	 
47	1789.338134765625	0.0	0.0	 
48	1751.07080078125	0.0	0.0	 
49	1713.658203125	0.0	0.0	 
50	1668.7396240234375	0.0	0.0	 
51	1620.3114013671875	0.0	0.0	 
52	1580.017578125	0.0	0.0	 
53	1535.645263671875	0.0	0.0	 
54	1504.1732177734375	0.0	0.0	 
55	1493.5543212890625	0.0	0.0	 
56	1476.2606201171875	0.0	0.0	 
57	1453.9957275390625	0.0	0.0	 
58	1428.390869140625	0.0	0.0	 
59	1400.948486328125	0.0	0.0	 
60	1380.8145751953125	0.0	0.0	 
61	1364.5328369140625	0.0	0.0	 
62	1347.5716552734375	0.0	0.0	 
63	1329.6300048828125	0.0	0.0	 
64	1317.641845703125	0.0	0.0	 
65	1305.6424560546875	0.0	0.0	 
66	1300.6602783203125	0.0	0.0	 
67	1290.237060546875	0.0	0.0	 
68	1282.6884765625	0.0	0.0	 
69	1271.610107421875	0.0	0.0	 
70	1267.34521484375	0.0	0.0	 
71	1260.6968994140625	0.0	0.0	 
72	1257.3739013671875	0.0	0.0	 
73	1251.1805419921875	0.0	0.0	 
74	1242.3564453125	0.0	0.0	 
75	1228.354736328125	0.0	0.0	 
76	1212.0076904296875	0.0	0.0	 
77	1195.5958251953125	0.0	0.0	 
78	1181.134765625	0.0	0.0	 
79	1169.5906982421875	0.0	0.0	 
80	1157.3431396484375	0.0	0.0	 
81	1142.5650634765625	0.0	0.0	 
82	1123.76513671875	0.0	0.0	 
83	1113.4617919921875	0.0	0.0	 
84	1098.6676025390625	0.0	0.0	 
85	1092.910400390625	0.0	0.0	 
86	1089.6988525390625	0.0	0.0	 
87	1070.1002197265625	0.0	0.0	 
88	1061.3192138671875	0.0	0.0	 
89	1040.873779296875	0.0	0.0	 
90	1031.3692626953125	0.0	0.0	 
91	1023.72265625	0.0	0.0	 
92	1010.8914794921875	0.0	0.0	 
93	1005.5095825195312	0.0	0.0	 
94	999.2103271484375	0.0	0.0	 
95	984.7950439453125	0.0	0.0	 
96	963.3211059570312	0.0	0.0	 
97	950.9429931640625	0.0	0.0	 
98	943.923095703125	0.0	0.0	 
99	931.5582885742188	0.0	0.0	 
100	16.167781829833984	0.0	0.0	 
101	16.034658432006836	0.0	0.0	 
102	15.95969295501709	0.0	0.0	 
103	15.864969253540039	0.0	0.0	 
104	15.803390502929688	0.0	0.0	 
105	15.753714561462402	0.0	0.0	 
106	15.695265769958496	0.0	0.0	 
107	15.583581924438477	0.0	0.0	 
108	15.442757606506348	0.0	0.0	 
109	15.303064346313477	0.0	0.0	 
110	15.245205879211426	0.0	0.0	 
111	15.172769546508789	0.0	0.0	 
112	15.128152847290039	0.0	0.0	 
113	15.030174255371094	0.0	0.0	 
114	14.92208194732666	0.0	0.0	 
115	14.88528060913086	0.0	0.0	 
116	14.773527145385742	0.0	0.0	 
117	14.700322151184082	0.0	0.0	 
118	14.639162063598633	0.0	0.0	 
119	14.570443153381348	0.0	0.0	 
120	14.418233871459961	0.0	0.0	 
121	14.354045867919922	0.0	0.0	 
122	14.301466941833496	0.0	0.0	 
123	14.247594833374023	0.0	0.0	 
124	14.155213356018066	0.0	0.0	 
125	14.080819129943848	0.0	0.0	 
126	14.021234512329102	0.0	0.0	 
127	13.982340812683105	0.0	0.0	 
